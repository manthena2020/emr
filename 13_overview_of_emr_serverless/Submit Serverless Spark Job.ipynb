{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Submitting Spark Application on EMR Serverless.\n",
    "```shell\n",
    "aws emr-serverless start-job-run \\\n",
    "    --application-id 00f1uur2ps283a09 \\\n",
    "    --execution-role-arn arn:aws:iam::269066542444:role/EMRServerlessS3RuntimeRole \\\n",
    "    --job-driver '{\n",
    "        \"sparkSubmit\": {\n",
    "            \"entryPoint\": \"/usr/lib/spark/examples/jars/spark-examples.jar\",\n",
    "            \"entryPointArguments\": [\"1\"],\n",
    "            \"sparkSubmitParameters\": \"--class org.apache.spark.examples.SparkPi --conf spark.executor.cores=4 --conf spark.executor.memory=20g --conf spark.driver.cores=4 --conf spark.driver.memory=8g --conf spark.executor.instances=1\"\n",
    "        }\n",
    "    }'\n",
    "```\n",
    "\n",
    "* Submitting Spark SQL Script as step on AWS EMR.\n",
    "```shell\n",
    "aws emr-serverless start-job-run \\\n",
    "    --application-id 00f1uur2ps283a09 \\\n",
    "    --execution-role-arn arn:aws:iam::269066542444:role/EMRServerlessS3RuntimeRole \\\n",
    "    --job-driver '{\n",
    "        \"sparkSubmit\": {\n",
    "            \"entryPoint\": \"s3://airetail/jars/command-runn.jar\",\n",
    "            \"sparkSubmitParameters\": \"spark-sql -d s3.bucket=airetail -f s3://airetail/scripts/compute_order_revenue.sql\"\n",
    "        }\n",
    "    }'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = boto3.client('emr-serverless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0326ade9-bdb3-4fad-8334-4a4f930e6824',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 20 Jul 2022 01:07:30 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '306',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '0326ade9-bdb3-4fad-8334-4a4f930e6824',\n",
       "   'x-amzn-remapped-x-amzn-requestid': 'VipE6Ej7oAMFSCg=',\n",
       "   'x-amzn-remapped-content-length': '306',\n",
       "   'x-amz-apigw-id': 'VipE6Ej7oAMFSCg=',\n",
       "   'x-amzn-trace-id': 'Root=1-62d75552-77b2ebe81de50b845f1f3adb',\n",
       "   'x-amzn-remapped-date': 'Wed, 20 Jul 2022 01:07:30 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'applications': [{'id': '00f1uur2ps283a09',\n",
       "   'name': 'GettingStarted',\n",
       "   'arn': 'arn:aws:emr-serverless:us-east-1:269066542444:/applications/00f1uur2ps283a09',\n",
       "   'releaseLabel': 'emr-6.6.0',\n",
       "   'type': 'Spark',\n",
       "   'state': 'STOPPED',\n",
       "   'stateDetails': '',\n",
       "   'createdAt': datetime.datetime(2022, 6, 24, 5, 19, 4, 627000, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2022, 7, 18, 21, 36, 26, 791000, tzinfo=tzlocal())}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.list_applications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mes_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_job_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Starts a job run.\n",
      "\n",
      "\n",
      "\n",
      "See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/emr-serverless-2021-07-13/StartJobRun>`_\n",
      "\n",
      "\n",
      "**Request Syntax** \n",
      "::\n",
      "\n",
      "  response = client.start_job_run(\n",
      "      applicationId='string',\n",
      "      clientToken='string',\n",
      "      executionRoleArn='string',\n",
      "      jobDriver={\n",
      "          'sparkSubmit': {\n",
      "              'entryPoint': 'string',\n",
      "              'entryPointArguments': [\n",
      "                  'string',\n",
      "              ],\n",
      "              'sparkSubmitParameters': 'string'\n",
      "          },\n",
      "          'hive': {\n",
      "              'query': 'string',\n",
      "              'initQueryFile': 'string',\n",
      "              'parameters': 'string'\n",
      "          }\n",
      "      },\n",
      "      configurationOverrides={\n",
      "          'applicationConfiguration': [\n",
      "              {\n",
      "                  'classification': 'string',\n",
      "                  'properties': {\n",
      "                      'string': 'string'\n",
      "                  },\n",
      "                  'configurations': {'... recursive ...'}\n",
      "              },\n",
      "          ],\n",
      "          'monitoringConfiguration': {\n",
      "              's3MonitoringConfiguration': {\n",
      "                  'logUri': 'string',\n",
      "                  'encryptionKeyArn': 'string'\n",
      "              },\n",
      "              'managedPersistenceMonitoringConfiguration': {\n",
      "                  'enabled': True|False,\n",
      "                  'encryptionKeyArn': 'string'\n",
      "              }\n",
      "          }\n",
      "      },\n",
      "      tags={\n",
      "          'string': 'string'\n",
      "      },\n",
      "      executionTimeoutMinutes=123,\n",
      "      name='string'\n",
      "  )\n",
      ":type applicationId: string\n",
      ":param applicationId: **[REQUIRED]** \n",
      "\n",
      "  The ID of the application on which to run the job.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      ":type clientToken: string\n",
      ":param clientToken: **[REQUIRED]** \n",
      "\n",
      "  The client idempotency token of the job run to start. Its value must be unique for each request.\n",
      "\n",
      "  This field is autopopulated if not provided.\n",
      "\n",
      "\n",
      ":type executionRoleArn: string\n",
      ":param executionRoleArn: **[REQUIRED]** \n",
      "\n",
      "  The execution role ARN for the job run.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      ":type jobDriver: dict\n",
      ":param jobDriver: \n",
      "\n",
      "  The job driver for the job run.\n",
      "\n",
      "  .. note::    This is a Tagged Union structure. Only one of the     following top level keys can be set: ``sparkSubmit``, ``hive``. \n",
      "\n",
      "\n",
      "  - **sparkSubmit** *(dict) --* \n",
      "\n",
      "    The job driver parameters specified for Spark.\n",
      "\n",
      "    \n",
      "\n",
      "  \n",
      "    - **entryPoint** *(string) --* **[REQUIRED]** \n",
      "\n",
      "      The entry point for the Spark submit job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "    - **entryPointArguments** *(list) --* \n",
      "\n",
      "      The arguments for the Spark submit job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "      - *(string) --* \n",
      "\n",
      "      \n",
      "  \n",
      "    - **sparkSubmitParameters** *(string) --* \n",
      "\n",
      "      The parameters for the Spark submit job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "  \n",
      "  - **hive** *(dict) --* \n",
      "\n",
      "    The job driver parameters specified for Hive.\n",
      "\n",
      "    \n",
      "\n",
      "  \n",
      "    - **query** *(string) --* **[REQUIRED]** \n",
      "\n",
      "      The query for the Hive job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "    - **initQueryFile** *(string) --* \n",
      "\n",
      "      The query file for the Hive job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "    - **parameters** *(string) --* \n",
      "\n",
      "      The parameters for the Hive job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "  \n",
      "\n",
      ":type configurationOverrides: dict\n",
      ":param configurationOverrides: \n",
      "\n",
      "  The configuration overrides for the job run.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "  - **applicationConfiguration** *(list) --* \n",
      "\n",
      "    The override configurations for the application.\n",
      "\n",
      "    \n",
      "\n",
      "  \n",
      "    - *(dict) --* \n",
      "\n",
      "      A configuration specification to be used when provisioning an application. A configuration consists of a classification, properties, and optional nested configurations. A classification refers to an application-specific configuration file. Properties are the settings you want to change in that file.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "      - **classification** *(string) --* **[REQUIRED]** \n",
      "\n",
      "        The classification within a configuration.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "      - **properties** *(dict) --* \n",
      "\n",
      "        A set of properties specified within a configuration classification.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "        - *(string) --* \n",
      "\n",
      "        \n",
      "          - *(string) --* \n",
      "\n",
      "          \n",
      "    \n",
      "  \n",
      "      - **configurations** *(list) --* \n",
      "\n",
      "        A list of additional configurations to apply within a configuration object.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "    \n",
      "\n",
      "  - **monitoringConfiguration** *(dict) --* \n",
      "\n",
      "    The override configurations for monitoring.\n",
      "\n",
      "    \n",
      "\n",
      "  \n",
      "    - **s3MonitoringConfiguration** *(dict) --* \n",
      "\n",
      "      The Amazon S3 configuration for monitoring log publishing.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "      - **logUri** *(string) --* \n",
      "\n",
      "        The Amazon S3 destination URI for log publishing.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "      - **encryptionKeyArn** *(string) --* \n",
      "\n",
      "        The KMS key ARN to encrypt the logs published to the given Amazon S3 destination.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "    \n",
      "    - **managedPersistenceMonitoringConfiguration** *(dict) --* \n",
      "\n",
      "      The managed log persistence configuration for a job run.\n",
      "\n",
      "      \n",
      "\n",
      "    \n",
      "      - **enabled** *(boolean) --* \n",
      "\n",
      "        Enables managed logging and defaults to true. If set to false, managed logging will be turned off.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "      - **encryptionKeyArn** *(string) --* \n",
      "\n",
      "        The KMS key ARN to encrypt the logs stored in managed log persistence.\n",
      "\n",
      "        \n",
      "\n",
      "      \n",
      "    \n",
      "  \n",
      "\n",
      ":type tags: dict\n",
      ":param tags: \n",
      "\n",
      "  The tags assigned to the job run.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "  - *(string) --* \n",
      "\n",
      "  \n",
      "    - *(string) --* \n",
      "\n",
      "    \n",
      "\n",
      "\n",
      ":type executionTimeoutMinutes: integer\n",
      ":param executionTimeoutMinutes: \n",
      "\n",
      "  The maximum duration for the job run to run. If the job run runs beyond this duration, it will be automatically cancelled.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      ":type name: string\n",
      ":param name: \n",
      "\n",
      "  The optional job run name. This doesn't have to be unique.\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      ":rtype: dict\n",
      ":returns: \n",
      "  \n",
      "  **Response Syntax** \n",
      "\n",
      "  \n",
      "  ::\n",
      "\n",
      "    {\n",
      "        'applicationId': 'string',\n",
      "        'jobRunId': 'string',\n",
      "        'arn': 'string'\n",
      "    }\n",
      "  **Response Structure** \n",
      "\n",
      "  \n",
      "\n",
      "  - *(dict) --* \n",
      "    \n",
      "\n",
      "    - **applicationId** *(string) --* \n",
      "\n",
      "      This output displays the application ID on which the job run was submitted.\n",
      "\n",
      "      \n",
      "    \n",
      "\n",
      "    - **jobRunId** *(string) --* \n",
      "\n",
      "      The output contains the ID of the started job run.\n",
      "\n",
      "      \n",
      "    \n",
      "\n",
      "    - **arn** *(string) --* \n",
      "\n",
      "      The output lists the execution role ARN of the job run.\n",
      "\n",
      "      \n",
      "\u001b[0;31mFile:\u001b[0m      ~/Projects/Internal/bootcamp/itversity-material/mastering-emr/me-venv/lib/python3.9/site-packages/botocore/client.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "es_client.start_job_run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0ca9b9c8-4b2c-40ea-8e2e-40520e843380',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 20 Jul 2022 02:38:19 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '176',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '0ca9b9c8-4b2c-40ea-8e2e-40520e843380',\n",
       "   'x-amzn-remapped-x-amzn-requestid': 'Vi2YSFRioAMFjVA=',\n",
       "   'x-amzn-remapped-content-length': '176',\n",
       "   'x-amz-apigw-id': 'Vi2YSFRioAMFjVA=',\n",
       "   'x-amzn-trace-id': 'Root=1-62d76a9b-02e053dc76b9f8c725544e59',\n",
       "   'x-amzn-remapped-date': 'Wed, 20 Jul 2022 02:38:19 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'applicationId': '00f1uur2ps283a09',\n",
       " 'jobRunId': '00f2jvb8le2hlk01',\n",
       " 'arn': 'arn:aws:emr-serverless:us-east-1:269066542444:/applications/00f1uur2ps283a09/jobruns/00f2jvb8le2hlk01'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.start_job_run(\n",
    "    applicationId='00f1uur2ps283a09',\n",
    "    executionRoleArn='arn:aws:iam::269066542444:role/EMRServerlessS3RuntimeRole',\n",
    "    jobDriver={\n",
    "        \"sparkSubmit\": {\n",
    "            \"entryPoint\": \"/usr/lib/spark/examples/jars/spark-examples.jar\",\n",
    "            \"entryPointArguments\": [\"1\"],\n",
    "            \"sparkSubmitParameters\": \"--class org.apache.spark.examples.SparkPi --conf spark.executor.cores=4 --conf spark.executor.memory=20g --conf spark.driver.cores=4 --conf spark.driver.memory=8g --conf spark.executor.instances=1\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ff09c89d-5e90-4323-90f5-f52ece456653',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 20 Jul 2022 01:20:43 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1122',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'ff09c89d-5e90-4323-90f5-f52ece456653',\n",
       "   'x-amzn-remapped-x-amzn-requestid': 'VirA1Ec-oAMFXHw=',\n",
       "   'x-amzn-remapped-content-length': '1054',\n",
       "   'x-amz-apigw-id': 'VirA1Ec-oAMFXHw=',\n",
       "   'x-amzn-trace-id': 'Root=1-62d7586b-6be15b716e2876895223f07b',\n",
       "   'x-amzn-remapped-date': 'Wed, 20 Jul 2022 01:20:43 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobRun': {'applicationId': '00f1uur2ps283a09',\n",
       "  'jobRunId': '00f2jttd4ijc1t01',\n",
       "  'arn': 'arn:aws:emr-serverless:us-east-1:269066542444:/applications/00f1uur2ps283a09/jobruns/00f2jttd4ijc1t01',\n",
       "  'createdBy': 'arn:aws:iam::269066542444:user/durga.gadiraju',\n",
       "  'createdAt': datetime.datetime(2022, 7, 20, 6, 48, 10, 593000, tzinfo=tzlocal()),\n",
       "  'updatedAt': datetime.datetime(2022, 7, 20, 6, 49, 58, 456000, tzinfo=tzlocal()),\n",
       "  'executionRole': 'arn:aws:iam::269066542444:role/EMRServerlessS3RuntimeRole',\n",
       "  'state': 'RUNNING',\n",
       "  'stateDetails': '',\n",
       "  'releaseLabel': 'emr-6.6.0',\n",
       "  'jobDriver': {'sparkSubmit': {'entryPoint': '/usr/lib/spark/examples/jars/spark-examples.jar',\n",
       "    'entryPointArguments': ['1'],\n",
       "    'sparkSubmitParameters': '--class org.apache.spark.examples.SparkPi --conf spark.executor.cores=4 --conf spark.executor.memory=20g --conf spark.driver.cores=4 --conf spark.driver.memory=8g --conf spark.executor.instances=1'}},\n",
       "  'tags': {}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.get_job_run(\n",
    "    applicationId='00f1uur2ps283a09',\n",
    "    jobRunId='00f2jttd4ijc1t01'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('me-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "486bfb5c5bc2d80b6bdfdd884fe8070e0b9ef1b20f462b79720291b7c17c500c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
